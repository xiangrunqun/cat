<property>
        <name>dfs.replication</name>
        <value>1</value>
    </property>




    ssh-keygen -t rsa -P '' -f ~/.ssh/id_rsa && cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys && chmod 0600 ~/.ssh/authorized_keys



    firewall-cmd --get-default-zone


    firewall-cmd --get-active-zones

    firewall-cmd --zone=public --add-port=9864/tcp && firewall-cmd --zone=public --permanent --add-port=9864/tcp && firewall-cmd --reload

    firewall-cmd --permanent --remove-port=9866/tcp && firewall-cmd --reload


  <property>
    <name>dfs.name.dir</name>
    <value>/root/hadoop/data/nn</value>
  </property>
  <property>
    <name>dfs.data.dir</name>
    <value>/root/hadoop/data/dn</value>
  </property>

rm: Cannot delete /user/root/hadoop-3.0.0-alpha1.tar.gz. Name node is in safe mode.


server 0.asia.pool.ntp.org
server 1.asia.pool.ntp.org
server 2.asia.pool.ntp.org
server 3.asia.pool.ntp.org


开启9000防火墙，不然datanode显示不了。

dfs.permissions.enabled  false


org.apache.hadoop.ipc.RemoteException: File /data could only be replicated to 0 nodes instead of minReplication (=1).  There are 1 datanode(s) running and 1 node(s) are excluded in this operation.



hadoop HA --> switch between two namenode of difference machine..
The HDFS High Availability feature addresses the above problems by providing the option of running two (and as of 3.0.0 more than two) redundant NameNodes in the same cluster in an Active/Passive configuration with a hot standby. This allows a fast failover to a new NameNode in the case that a machine crashes, or a graceful administrator-initiated failover for the purpose of planned maintenance.

hadoop federation --> switch between two namenode of one machine..
The prior HDFS architecture allows only a single namespace for the entire cluster. In that configuration, a single Namenode manages the namespace. HDFS Federation addresses this limitation by adding support for multiple Namenodes/namespaces to HDFS.


