<property>
        <name>dfs.replication</name>
        <value>1</value>
    </property>




    ssh-keygen -t rsa -P '' -f ~/.ssh/id_rsa && cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys && chmod 0600 ~/.ssh/authorized_keys



    firewall-cmd --get-default-zone


    firewall-cmd --get-active-zones

    firewall-cmd --zone=public --add-port=9864/tcp && firewall-cmd --zone=public --permanent --add-port=9864/tcp && firewall-cmd --reload

    firewall-cmd --permanent --remove-port=9866/tcp && firewall-cmd --reload


  <property>
    <name>dfs.name.dir</name>
    <value>/root/hadoop/data/nn</value>
  </property>
  <property>
    <name>dfs.data.dir</name>
    <value>/root/hadoop/data/dn</value>
  </property>

rm: Cannot delete /user/root/hadoop-3.0.0-alpha1.tar.gz. Name node is in safe mode.


server 0.asia.pool.ntp.org
server 1.asia.pool.ntp.org
server 2.asia.pool.ntp.org
server 3.asia.pool.ntp.org


开启9000防火墙，不然datanode显示不了。

dfs.permissions.enabled  false

org.apache.hadoop.ipc.RemoteException: File /data could only be replicated to 0 nodes instead of minReplication (=1).  There are 1 datanode(s) running and 1 node(s) are excluded in this operation.


-- 动态添加删除datanode节点
   删除节点
      hdfs-core.xml 文件配置属性 dfs.hosts.exclude 并在这个文件中添加datanode的ip
   添加节点
      hdfs-core.xml 文件配置属性 dfs.hosts 并在这个文件中添加datanode的ip
      启动新添加机器的datanode daemon。bin/hdfs --daemon start datanode
  
   以上的配置文件修改以后需要使用命令进行refresh。 bin/hdfs dfsadmin -refreshNodes




-- 高可用配置
hadoop HA --> switch between two namenode of difference machine..
The HDFS High Availability feature addresses the above problems by providing the option of running two (and as of 3.0.0 more than two) redundant NameNodes in the same cluster in an Active/Passive configuration with a hot standby. This allows a fast failover to a new NameNode in the case that a machine crashes, or a graceful administrator-initiated failover for the purpose of planned maintenance.

hadoop federation --> switch between two namenode of one machine..
The prior HDFS architecture allows only a single namespace for the entire cluster. In that configuration, a single Namenode manages the namespace. HDFS Federation addresses this limitation by adding support for multiple Namenodes/namespaces to HDFS.


